{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xmf/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path of pycaffe /home/xmf/BVLC_caffe/caffe/python\n",
      "caffe module is imported\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "CAFFE_ROOT = '/home/xmf/BVLC_caffe/caffe/'     # please change it to your caffe root directory\n",
    "import os, sys\n",
    "CAFFE_PYTHON_DIR = os.path.join(CAFFE_ROOT, 'python')\n",
    "print 'path of pycaffe {}'.format(CAFFE_PYTHON_DIR)\n",
    "sys.path.insert(0, CAFFE_PYTHON_DIR)\n",
    "import caffe\n",
    "print 'caffe module is imported'\n",
    "\n",
    "caffe.set_mode_gpu()   # if you don't have gpu, change gpu to cpu\n",
    "\n",
    "IMAGE_SIZE = (28, 28,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 介绍 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST是LeCun为了美国邮政系统手写数字识别问题而建立的数据集。自那以后，很多的学者提出了不同的方法不断提升识别精度，LeCun也针对这个问题提出了经典的卷积神经网络。这篇博客就是希望借助求解Kaggle平台上的MNIST竞赛，梳理使用Caffe实现基于卷积神经网络的手写数字识别的过程。\n",
    "\n",
    "MNIST is a large database of handwritten digits established by LeCun. Many researchers have proposed different methods to increase the accurancy since then. LeCun gave a solution based on convolutional neural network, which is considered to be the first successful application of convolutional neural network case. This blog is to record how to use Caffe to implement a convolutional neural network for hand writing digits recongnization in Kaggle.\n",
    "\n",
    "在[Kaggle](https://www.kaggle.com/c/digit-recognizer)的网站上，MNIST的数据是通过CSV文件给出的。对于训练所用文件train.csv，每行由28x28+1个数字组成。第一个数字为该训练样本对应的数字，后面的28x28个数字在0到255之间，代表训练样本的图像从上到下，从左到右各个像素的灰度值。测试所用文件test.csv则每行只有28x28个数字，相比训练样本，缺少了对应的标签。我们需要使用训练样本进行训练网络模型，再对应给出各个测试样例的对应预测标签，同样写入一个csv文件，并提交。\n",
    "\n",
    "In [Kaggle](https://www.kaggle.com/c/digit-recognizer), the dataset is given by CSV files. For the training file train.csv, there are (28x28+1) numbers in each row. The first number is the label, and the following numbers are in the range [0, 255], giving the grayscale value for each pixel in the images. The testing file test.csv has 28x28 numbers in each row, lack of labels compared with training file. We need to train our model using the trainning samples and predict the labels for testing individuals. The results shoule be saved in a CSV file and submitted to the website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取数据 Data Acquirement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们需要在网上下载数据，分别是train.csv, test.csv，将它们放到 ./data/文件夹下。\n",
    "\n",
    "First, we need to download dataset from website. Put them in ./data/ directory. \n",
    "\n",
    "我没有使用pandas解析文件，使用下面的函数可以将每一行除去标签之外的28x28个数转换为numpy中的二维数组。\n",
    "\n",
    "I don't use pandas to parse the csv file. The following function can be uesd to parse the row excluding the label to 2D array in numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_image(line):\n",
    "    \"\"\"\n",
    "    get the 2D array from txt\n",
    "    \"\"\"\n",
    "    data = [float(x) for x in line.split(',')]\n",
    "    assert len(data) == IMAGE_SIZE[0] * IMAGE_SIZE[1]\n",
    "    return np.array(data, dtype = np.float32).reshape(IMAGE_SIZE)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来随机选择3张训练用图像进行可视化。\n",
    "\n",
    "Let‘s take a look at 3 images chosen randomly from the training list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 3 example images of size (28x28).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAACNCAYAAAB8MisUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fda6d914790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_file = './data/train.csv'\n",
    "test_file = './data/test.csv'\n",
    "# read the trainning list from file\n",
    "with open(train_file, 'r') as f:\n",
    "    f.readline()    # skip the annotation\n",
    "    train_list = f.readlines()\n",
    "np.random.shuffle(train_list)\n",
    "example_n = 3\n",
    "examples = train_list[:example_n]\n",
    "images = np.empty((example_n, ) + IMAGE_SIZE, dtype = np.uint8)\n",
    "labels = np.empty(example_n, dtype = int)\n",
    "for i, line in enumerate(examples):\n",
    "    labels[i] = int(line[0])\n",
    "    line = line[2:]   # skip the label and the first comma\n",
    "    images[i] = get_image(line).astype(np.uint8)\n",
    "\n",
    "print 'there are {0} example images of size ({1}x{2}).'.format(example_n, IMAGE_SIZE[0], IMAGE_SIZE[1])\n",
    "plt.figure()\n",
    "for i, im in enumerate(images):\n",
    "    plt.subplot(1, example_n, i+1)\n",
    "    plt.imshow(im, cmap = 'gray')\n",
    "    plt.title('label:{}'.format(labels[i]))\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建卷积神经网络 Build CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个例子中，我只是很随便地设计了一个卷积网络。使用Caffe中的API将网络结构可视化，存储到./net文件夹下。\n",
    "\n",
    "In this demo, I designed a vanilla CNN for this task. I use API in Caffe to visualize the net structure, and you can find the picture in ./net directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net_define_file = './net/train_val.prototxt'   # the prototxt file describing the structure of the network\n",
    "phase = caffe.TRAIN                                        # training phase\n",
    "output_file_name = './net/train_net.png'\n",
    "import caffe.draw\n",
    "from google.protobuf import text_format\n",
    "from caffe.proto import caffe_pb2\n",
    "net = caffe_pb2.NetParameter()\n",
    "text_format.Merge(open(net_define_file).read(), net)\n",
    "caffe.draw.draw_net_to_file(net, output_file_name, phase)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了方便，我直接使用了HDF5作为数据的输入接口。将所有训练样本读取出来，存成HDF5文件。Caffe的数据输入层定义为HDF5Data就可以了。\n",
    "\n",
    "For convinence, I used HDF5DataLayer as input interface of the net. So we need to generate HDF5 files from the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 42000 images totally.\n",
      "total train samples: 33600\n",
      "total val_sample: 8400\n",
      "processing train part\n",
      "-------------------------------\n",
      "output h5 file name:/home/xmf/github/kaggle_mnist/data/train.h5\n",
      "processed 5000 images.\n",
      "processed 10000 images.\n",
      "processed 15000 images.\n",
      "processed 20000 images.\n",
      "processed 25000 images.\n",
      "processed 30000 images.\n",
      "process train done.\n",
      "processing val part\n",
      "-------------------------------\n",
      "output h5 file name:/home/xmf/github/kaggle_mnist/data/val.h5\n",
      "processed 5000 images.\n",
      "process val done.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import cv2\n",
    "train_part = 0.8   # we use 80% of total samples as training\n",
    "\n",
    "def get_h5_file(phase, lines, output_dir):\n",
    "    \"\"\"\n",
    "    generate hdf5 files in output_dir directory\n",
    "    \"\"\"\n",
    "    assert phase == 'train' or phase == 'val'\n",
    "    print 'processing {0} part'.format(phase)\n",
    "    print '-------------------------------' \n",
    "    total_number = len(lines)\n",
    "    imgs = np.empty((total_number, 1,) +  IMAGE_SIZE, dtype = np.float32)\n",
    "    labels = np.empty((total_number, 1), dtype = np.float32)\n",
    "    cols = IMAGE_SIZE[0] * IMAGE_SIZE[1] + 1\n",
    "    h5_file_name = os.path.join(output_dir, '{0}.h5'.format(phase))\n",
    "    print 'output h5 file name:{0}'.format(h5_file_name)\n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        splited = line.split(',')\n",
    "        assert len(splited) == cols\n",
    "        data = [float(x) for x in splited[1:]]\n",
    "        label = int(splited[0])\n",
    "        assert 0 <= label <= 9 \n",
    "        labels[i, 0] = label\n",
    "        imgs[i] = np.array(data).reshape((1,) + IMAGE_SIZE)\n",
    "        if (i +1) % 5000 == 0:\n",
    "            print 'processed {0} images.'.format(i+1)\n",
    "        imgs[i] -= 128.0\n",
    "        imgs[i] /= 255.0\n",
    "    with h5py.File(h5_file_name, 'w') as h:\n",
    "        h.create_dataset('data', data = imgs)\n",
    "        h.create_dataset('label', data = labels)\n",
    "    with open(os.path.join(output_dir, '{0}_h5.txt').format(phase), 'w') as f:\n",
    "        f.write(h5_file_name)\n",
    "    print 'process {0} done.'.format(phase)\n",
    "    \n",
    "def process(csv_file, output_dir):\n",
    "    \"\"\"\n",
    "    read samples from the csv file and save the data into hdf5 files \n",
    "    \"\"\"\n",
    "    name, ext = os.path.splitext(csv_file)\n",
    "    assert ext == '.csv'\n",
    "    with open(csv_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    lines = lines[1:]\n",
    "    total_number = len(lines)\n",
    "    print 'there are {0} images totally.'.format(total_number)\n",
    "    \n",
    "    np.random.shuffle(lines)\n",
    "    train_number = int(total_number * train_part)\n",
    "    val_number = total_number - train_number\n",
    "    print 'total train samples: {0}'.format(train_number)\n",
    "    print 'total val_sample: {0}'.format(val_number)\n",
    "    train_lines = lines[:train_number]\n",
    "    val_lines = lines[train_number:]\n",
    "    assert len(val_lines) == val_number\n",
    "    get_h5_file('train', train_lines, output_dir)\n",
    "    get_h5_file('val', val_lines, output_dir)\n",
    "    \n",
    "file_name = './data/train.csv'\n",
    "full_file_name = os.path.abspath(file_name)\n",
    "path, _ = os.path.split(full_file_name)\n",
    "process(full_file_name, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练 Train CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用./scripts/train.sh脚本训练网络，注意修改其中caffe的路径。\n",
    "\n",
    "Use train.sh to train the network. Please change CAFFE path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0903 22:45:00.014075  3004 caffe.cpp:192] Using GPUs 0\n",
      "I0903 22:45:00.021977  3004 caffe.cpp:197] GPU 0: GeForce GTX 960M\n",
      "I0903 22:45:00.399430  3004 solver.cpp:48] Initializing solver from parameters: \n",
      "test_iter: 600\n",
      "test_interval: 5000\n",
      "base_lr: 0.001\n",
      "display: 5000\n",
      "max_iter: 20000\n",
      "lr_policy: \"step\"\n",
      "gamma: 0.1\n",
      "momentum: 0.9\n",
      "weight_decay: 0.0005\n",
      "stepsize: 20000\n",
      "snapshot: 5000\n",
      "snapshot_prefix: \"./models/mnist\"\n",
      "solver_mode: GPU\n",
      "device_id: 0\n",
      "net: \"./net/train_val.prototxt\"\n",
      "I0903 22:45:00.399696  3004 solver.cpp:91] Creating training net from net file: ./net/train_val.prototxt\n",
      "I0903 22:45:00.400514  3004 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data\n",
      "I0903 22:45:00.400562  3004 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy\n",
      "I0903 22:45:00.400753  3004 net.cpp:49] Initializing net from parameters: \n",
      "name: \"mnist-net\"\n",
      "state {\n",
      "  phase: TRAIN\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"HDF5Data\"\n",
      "  top: \"data\"\n",
      "  top: \"label\"\n",
      "  include {\n",
      "    phase: TRAIN\n",
      "  }\n",
      "  hdf5_data_param {\n",
      "    source: \"./data/train_h5.txt\"\n",
      "    batch_size: 128\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 20\n",
      "    kernel_size: 5\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 50\n",
      "    kernel_size: 5\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ip1\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"ip1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 100\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"ip2\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 10\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"loss\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"ip2\"\n",
      "  bottom: \"label\"\n",
      "}\n",
      "I0903 22:45:00.400910  3004 layer_factory.hpp:77] Creating layer data\n",
      "I0903 22:45:00.400949  3004 net.cpp:91] Creating Layer data\n",
      "I0903 22:45:00.400969  3004 net.cpp:399] data -> data\n",
      "I0903 22:45:00.401024  3004 net.cpp:399] data -> label\n",
      "I0903 22:45:00.401063  3004 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: ./data/train_h5.txt\n",
      "I0903 22:45:00.401124  3004 hdf5_data_layer.cpp:93] Number of HDF5 files: 1\n",
      "I0903 22:45:00.403002  3004 hdf5.cpp:32] Datatype class: H5T_FLOAT\n",
      "I0903 22:45:00.578071  3004 net.cpp:141] Setting up data\n",
      "I0903 22:45:00.578142  3004 net.cpp:148] Top shape: 128 1 28 28 (100352)\n",
      "I0903 22:45:00.578163  3004 net.cpp:148] Top shape: 128 1 (128)\n",
      "I0903 22:45:00.578176  3004 net.cpp:156] Memory required for data: 401920\n",
      "I0903 22:45:00.578196  3004 layer_factory.hpp:77] Creating layer conv1\n",
      "I0903 22:45:00.578243  3004 net.cpp:91] Creating Layer conv1\n",
      "I0903 22:45:00.578264  3004 net.cpp:425] conv1 <- data\n",
      "I0903 22:45:00.578295  3004 net.cpp:399] conv1 -> conv1\n",
      "I0903 22:45:00.581105  3004 net.cpp:141] Setting up conv1\n",
      "I0903 22:45:00.581156  3004 net.cpp:148] Top shape: 128 20 24 24 (1474560)\n",
      "I0903 22:45:00.581169  3004 net.cpp:156] Memory required for data: 6300160\n",
      "I0903 22:45:00.581218  3004 layer_factory.hpp:77] Creating layer relu1\n",
      "I0903 22:45:00.581336  3004 net.cpp:91] Creating Layer relu1\n",
      "I0903 22:45:00.581358  3004 net.cpp:425] relu1 <- conv1\n",
      "I0903 22:45:00.581377  3004 net.cpp:386] relu1 -> conv1 (in-place)\n",
      "I0903 22:45:00.581410  3004 net.cpp:141] Setting up relu1\n",
      "I0903 22:45:00.581428  3004 net.cpp:148] Top shape: 128 20 24 24 (1474560)\n",
      "I0903 22:45:00.581437  3004 net.cpp:156] Memory required for data: 12198400\n",
      "I0903 22:45:00.581449  3004 layer_factory.hpp:77] Creating layer pool1\n",
      "I0903 22:45:00.581472  3004 net.cpp:91] Creating Layer pool1\n",
      "I0903 22:45:00.581485  3004 net.cpp:425] pool1 <- conv1\n",
      "I0903 22:45:00.581501  3004 net.cpp:399] pool1 -> pool1\n",
      "I0903 22:45:00.581620  3004 net.cpp:141] Setting up pool1\n",
      "I0903 22:45:00.581642  3004 net.cpp:148] Top shape: 128 20 12 12 (368640)\n",
      "I0903 22:45:00.581655  3004 net.cpp:156] Memory required for data: 13672960\n",
      "I0903 22:45:00.581665  3004 layer_factory.hpp:77] Creating layer conv2\n",
      "I0903 22:45:00.581691  3004 net.cpp:91] Creating Layer conv2\n",
      "I0903 22:45:00.581703  3004 net.cpp:425] conv2 <- pool1\n",
      "I0903 22:45:00.581720  3004 net.cpp:399] conv2 -> conv2\n",
      "I0903 22:45:00.582788  3004 net.cpp:141] Setting up conv2\n",
      "I0903 22:45:00.582878  3004 net.cpp:148] Top shape: 128 50 8 8 (409600)\n",
      "I0903 22:45:00.582898  3004 net.cpp:156] Memory required for data: 15311360\n",
      "I0903 22:45:00.582922  3004 layer_factory.hpp:77] Creating layer relu2\n",
      "I0903 22:45:00.582937  3004 net.cpp:91] Creating Layer relu2\n",
      "I0903 22:45:00.582952  3004 net.cpp:425] relu2 <- conv2\n",
      "I0903 22:45:00.582967  3004 net.cpp:386] relu2 -> conv2 (in-place)\n",
      "I0903 22:45:00.582983  3004 net.cpp:141] Setting up relu2\n",
      "I0903 22:45:00.582995  3004 net.cpp:148] Top shape: 128 50 8 8 (409600)\n",
      "I0903 22:45:00.583005  3004 net.cpp:156] Memory required for data: 16949760\n",
      "I0903 22:45:00.583019  3004 layer_factory.hpp:77] Creating layer pool2\n",
      "I0903 22:45:00.583034  3004 net.cpp:91] Creating Layer pool2\n",
      "I0903 22:45:00.583044  3004 net.cpp:425] pool2 <- conv2\n",
      "I0903 22:45:00.583057  3004 net.cpp:399] pool2 -> pool2\n",
      "I0903 22:45:00.583143  3004 net.cpp:141] Setting up pool2\n",
      "I0903 22:45:00.583163  3004 net.cpp:148] Top shape: 128 50 4 4 (102400)\n",
      "I0903 22:45:00.583173  3004 net.cpp:156] Memory required for data: 17359360\n",
      "I0903 22:45:00.583181  3004 layer_factory.hpp:77] Creating layer ip1\n",
      "I0903 22:45:00.583207  3004 net.cpp:91] Creating Layer ip1\n",
      "I0903 22:45:00.583219  3004 net.cpp:425] ip1 <- pool2\n",
      "I0903 22:45:00.583232  3004 net.cpp:399] ip1 -> ip1\n",
      "I0903 22:45:00.585921  3004 net.cpp:141] Setting up ip1\n",
      "I0903 22:45:00.585954  3004 net.cpp:148] Top shape: 128 100 (12800)\n",
      "I0903 22:45:00.585965  3004 net.cpp:156] Memory required for data: 17410560\n",
      "I0903 22:45:00.585994  3004 layer_factory.hpp:77] Creating layer relu1\n",
      "I0903 22:45:00.586015  3004 net.cpp:91] Creating Layer relu1\n",
      "I0903 22:45:00.586026  3004 net.cpp:425] relu1 <- ip1\n",
      "I0903 22:45:00.586040  3004 net.cpp:386] relu1 -> ip1 (in-place)\n",
      "I0903 22:45:00.586057  3004 net.cpp:141] Setting up relu1\n",
      "I0903 22:45:00.586074  3004 net.cpp:148] Top shape: 128 100 (12800)\n",
      "I0903 22:45:00.586083  3004 net.cpp:156] Memory required for data: 17461760\n",
      "I0903 22:45:00.586092  3004 layer_factory.hpp:77] Creating layer ip2\n",
      "I0903 22:45:00.586112  3004 net.cpp:91] Creating Layer ip2\n",
      "I0903 22:45:00.586124  3004 net.cpp:425] ip2 <- ip1\n",
      "I0903 22:45:00.586140  3004 net.cpp:399] ip2 -> ip2\n",
      "I0903 22:45:00.586381  3004 net.cpp:141] Setting up ip2\n",
      "I0903 22:45:00.586400  3004 net.cpp:148] Top shape: 128 10 (1280)\n",
      "I0903 22:45:00.586410  3004 net.cpp:156] Memory required for data: 17466880\n",
      "I0903 22:45:00.586426  3004 layer_factory.hpp:77] Creating layer loss\n",
      "I0903 22:45:00.586452  3004 net.cpp:91] Creating Layer loss\n",
      "I0903 22:45:00.586462  3004 net.cpp:425] loss <- ip2\n",
      "I0903 22:45:00.586473  3004 net.cpp:425] loss <- label\n",
      "I0903 22:45:00.586494  3004 net.cpp:399] loss -> (automatic)\n",
      "I0903 22:45:00.586532  3004 layer_factory.hpp:77] Creating layer loss\n",
      "I0903 22:45:00.587602  3004 net.cpp:141] Setting up loss\n",
      "I0903 22:45:00.587636  3004 net.cpp:148] Top shape: (1)\n",
      "I0903 22:45:00.587647  3004 net.cpp:151]     with loss weight 1\n",
      "I0903 22:45:00.587709  3004 net.cpp:156] Memory required for data: 17466884\n",
      "I0903 22:45:00.587729  3004 net.cpp:217] loss needs backward computation.\n",
      "I0903 22:45:00.587743  3004 net.cpp:217] ip2 needs backward computation.\n",
      "I0903 22:45:00.587751  3004 net.cpp:217] relu1 needs backward computation.\n",
      "I0903 22:45:00.587761  3004 net.cpp:217] ip1 needs backward computation.\n",
      "I0903 22:45:00.587774  3004 net.cpp:217] pool2 needs backward computation.\n",
      "I0903 22:45:00.587785  3004 net.cpp:217] relu2 needs backward computation.\n",
      "I0903 22:45:00.587795  3004 net.cpp:217] conv2 needs backward computation.\n",
      "I0903 22:45:00.587805  3004 net.cpp:217] pool1 needs backward computation.\n",
      "I0903 22:45:00.587815  3004 net.cpp:217] relu1 needs backward computation.\n",
      "I0903 22:45:00.587824  3004 net.cpp:217] conv1 needs backward computation.\n",
      "I0903 22:45:00.587836  3004 net.cpp:219] data does not need backward computation.\n",
      "I0903 22:45:00.587862  3004 net.cpp:274] Network initialization done.\n",
      "I0903 22:45:00.588624  3004 solver.cpp:181] Creating test net (#0) specified by net file: ./net/train_val.prototxt\n",
      "I0903 22:45:00.588695  3004 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data\n",
      "I0903 22:45:00.588906  3004 net.cpp:49] Initializing net from parameters: \n",
      "name: \"mnist-net\"\n",
      "state {\n",
      "  phase: TEST\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"HDF5Data\"\n",
      "  top: \"data\"\n",
      "  top: \"label\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "  hdf5_data_param {\n",
      "    source: \"./data/val_h5.txt\"\n",
      "    batch_size: 128\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 20\n",
      "    kernel_size: 5\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 50\n",
      "    kernel_size: 5\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ip1\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"ip1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 100\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"ip2\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 10\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"accuracy\"\n",
      "  type: \"Accuracy\"\n",
      "  bottom: \"ip2\"\n",
      "  bottom: \"label\"\n",
      "  top: \"accuracy\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"loss\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"ip2\"\n",
      "  bottom: \"label\"\n",
      "}\n",
      "I0903 22:45:00.589078  3004 layer_factory.hpp:77] Creating layer data\n",
      "I0903 22:45:00.589104  3004 net.cpp:91] Creating Layer data\n",
      "I0903 22:45:00.589121  3004 net.cpp:399] data -> data\n",
      "I0903 22:45:00.589144  3004 net.cpp:399] data -> label\n",
      "I0903 22:45:00.589166  3004 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: ./data/val_h5.txt\n",
      "I0903 22:45:00.589216  3004 hdf5_data_layer.cpp:93] Number of HDF5 files: 1\n",
      "I0903 22:45:00.620268  3004 net.cpp:141] Setting up data\n",
      "I0903 22:45:00.620321  3004 net.cpp:148] Top shape: 128 1 28 28 (100352)\n",
      "I0903 22:45:00.620338  3004 net.cpp:148] Top shape: 128 1 (128)\n",
      "I0903 22:45:00.620349  3004 net.cpp:156] Memory required for data: 401920\n",
      "I0903 22:45:00.620399  3004 layer_factory.hpp:77] Creating layer label_data_1_split\n",
      "I0903 22:45:00.620425  3004 net.cpp:91] Creating Layer label_data_1_split\n",
      "I0903 22:45:00.620442  3004 net.cpp:425] label_data_1_split <- label\n",
      "I0903 22:45:00.620460  3004 net.cpp:399] label_data_1_split -> label_data_1_split_0\n",
      "I0903 22:45:00.620483  3004 net.cpp:399] label_data_1_split -> label_data_1_split_1\n",
      "I0903 22:45:00.620563  3004 net.cpp:141] Setting up label_data_1_split\n",
      "I0903 22:45:00.620582  3004 net.cpp:148] Top shape: 128 1 (128)\n",
      "I0903 22:45:00.620594  3004 net.cpp:148] Top shape: 128 1 (128)\n",
      "I0903 22:45:00.620604  3004 net.cpp:156] Memory required for data: 402944\n",
      "I0903 22:45:00.620614  3004 layer_factory.hpp:77] Creating layer conv1\n",
      "I0903 22:45:00.620640  3004 net.cpp:91] Creating Layer conv1\n",
      "I0903 22:45:00.620651  3004 net.cpp:425] conv1 <- data\n",
      "I0903 22:45:00.620666  3004 net.cpp:399] conv1 -> conv1\n",
      "I0903 22:45:00.621265  3004 net.cpp:141] Setting up conv1\n",
      "I0903 22:45:00.621295  3004 net.cpp:148] Top shape: 128 20 24 24 (1474560)\n",
      "I0903 22:45:00.621305  3004 net.cpp:156] Memory required for data: 6301184\n",
      "I0903 22:45:00.621331  3004 layer_factory.hpp:77] Creating layer relu1\n",
      "I0903 22:45:00.621347  3004 net.cpp:91] Creating Layer relu1\n",
      "I0903 22:45:00.621359  3004 net.cpp:425] relu1 <- conv1\n",
      "I0903 22:45:00.621373  3004 net.cpp:386] relu1 -> conv1 (in-place)\n",
      "I0903 22:45:00.621395  3004 net.cpp:141] Setting up relu1\n",
      "I0903 22:45:00.621409  3004 net.cpp:148] Top shape: 128 20 24 24 (1474560)\n",
      "I0903 22:45:00.621459  3004 net.cpp:156] Memory required for data: 12199424\n",
      "I0903 22:45:00.621475  3004 layer_factory.hpp:77] Creating layer pool1\n",
      "I0903 22:45:00.621495  3004 net.cpp:91] Creating Layer pool1\n",
      "I0903 22:45:00.621505  3004 net.cpp:425] pool1 <- conv1\n",
      "I0903 22:45:00.621518  3004 net.cpp:399] pool1 -> pool1\n",
      "I0903 22:45:00.621608  3004 net.cpp:141] Setting up pool1\n",
      "I0903 22:45:00.621628  3004 net.cpp:148] Top shape: 128 20 12 12 (368640)\n",
      "I0903 22:45:00.621637  3004 net.cpp:156] Memory required for data: 13673984\n",
      "I0903 22:45:00.621647  3004 layer_factory.hpp:77] Creating layer conv2\n",
      "I0903 22:45:00.621670  3004 net.cpp:91] Creating Layer conv2\n",
      "I0903 22:45:00.621681  3004 net.cpp:425] conv2 <- pool1\n",
      "I0903 22:45:00.621696  3004 net.cpp:399] conv2 -> conv2\n",
      "I0903 22:45:00.622786  3004 net.cpp:141] Setting up conv2\n",
      "I0903 22:45:00.622831  3004 net.cpp:148] Top shape: 128 50 8 8 (409600)\n",
      "I0903 22:45:00.622843  3004 net.cpp:156] Memory required for data: 15312384\n",
      "I0903 22:45:00.622865  3004 layer_factory.hpp:77] Creating layer relu2\n",
      "I0903 22:45:00.622880  3004 net.cpp:91] Creating Layer relu2\n",
      "I0903 22:45:00.622891  3004 net.cpp:425] relu2 <- conv2\n",
      "I0903 22:45:00.622905  3004 net.cpp:386] relu2 -> conv2 (in-place)\n",
      "I0903 22:45:00.622925  3004 net.cpp:141] Setting up relu2\n",
      "I0903 22:45:00.622939  3004 net.cpp:148] Top shape: 128 50 8 8 (409600)\n",
      "I0903 22:45:00.622947  3004 net.cpp:156] Memory required for data: 16950784\n",
      "I0903 22:45:00.622956  3004 layer_factory.hpp:77] Creating layer pool2\n",
      "I0903 22:45:00.622969  3004 net.cpp:91] Creating Layer pool2\n",
      "I0903 22:45:00.622979  3004 net.cpp:425] pool2 <- conv2\n",
      "I0903 22:45:00.622993  3004 net.cpp:399] pool2 -> pool2\n",
      "I0903 22:45:00.623071  3004 net.cpp:141] Setting up pool2\n",
      "I0903 22:45:00.623090  3004 net.cpp:148] Top shape: 128 50 4 4 (102400)\n",
      "I0903 22:45:00.623100  3004 net.cpp:156] Memory required for data: 17360384\n",
      "I0903 22:45:00.623109  3004 layer_factory.hpp:77] Creating layer ip1\n",
      "I0903 22:45:00.623128  3004 net.cpp:91] Creating Layer ip1\n",
      "I0903 22:45:00.623141  3004 net.cpp:425] ip1 <- pool2\n",
      "I0903 22:45:00.623154  3004 net.cpp:399] ip1 -> ip1\n",
      "I0903 22:45:00.625010  3004 net.cpp:141] Setting up ip1\n",
      "I0903 22:45:00.625036  3004 net.cpp:148] Top shape: 128 100 (12800)\n",
      "I0903 22:45:00.625046  3004 net.cpp:156] Memory required for data: 17411584\n",
      "I0903 22:45:00.625068  3004 layer_factory.hpp:77] Creating layer relu1\n",
      "I0903 22:45:00.625082  3004 net.cpp:91] Creating Layer relu1\n",
      "I0903 22:45:00.625093  3004 net.cpp:425] relu1 <- ip1\n",
      "I0903 22:45:00.625108  3004 net.cpp:386] relu1 -> ip1 (in-place)\n",
      "I0903 22:45:00.625157  3004 net.cpp:141] Setting up relu1\n",
      "I0903 22:45:00.625171  3004 net.cpp:148] Top shape: 128 100 (12800)\n",
      "I0903 22:45:00.625181  3004 net.cpp:156] Memory required for data: 17462784\n",
      "I0903 22:45:00.625234  3004 layer_factory.hpp:77] Creating layer ip2\n",
      "I0903 22:45:00.625257  3004 net.cpp:91] Creating Layer ip2\n",
      "I0903 22:45:00.625269  3004 net.cpp:425] ip2 <- ip1\n",
      "I0903 22:45:00.625285  3004 net.cpp:399] ip2 -> ip2\n",
      "I0903 22:45:00.625535  3004 net.cpp:141] Setting up ip2\n",
      "I0903 22:45:00.625555  3004 net.cpp:148] Top shape: 128 10 (1280)\n",
      "I0903 22:45:00.625566  3004 net.cpp:156] Memory required for data: 17467904\n",
      "I0903 22:45:00.625581  3004 layer_factory.hpp:77] Creating layer ip2_ip2_0_split\n",
      "I0903 22:45:00.625594  3004 net.cpp:91] Creating Layer ip2_ip2_0_split\n",
      "I0903 22:45:00.625604  3004 net.cpp:425] ip2_ip2_0_split <- ip2\n",
      "I0903 22:45:00.625618  3004 net.cpp:399] ip2_ip2_0_split -> ip2_ip2_0_split_0\n",
      "I0903 22:45:00.625635  3004 net.cpp:399] ip2_ip2_0_split -> ip2_ip2_0_split_1\n",
      "I0903 22:45:00.625704  3004 net.cpp:141] Setting up ip2_ip2_0_split\n",
      "I0903 22:45:00.625720  3004 net.cpp:148] Top shape: 128 10 (1280)\n",
      "I0903 22:45:00.625731  3004 net.cpp:148] Top shape: 128 10 (1280)\n",
      "I0903 22:45:00.625741  3004 net.cpp:156] Memory required for data: 17478144\n",
      "I0903 22:45:00.625751  3004 layer_factory.hpp:77] Creating layer accuracy\n",
      "I0903 22:45:00.625777  3004 net.cpp:91] Creating Layer accuracy\n",
      "I0903 22:45:00.625788  3004 net.cpp:425] accuracy <- ip2_ip2_0_split_0\n",
      "I0903 22:45:00.625802  3004 net.cpp:425] accuracy <- label_data_1_split_0\n",
      "I0903 22:45:00.625820  3004 net.cpp:399] accuracy -> accuracy\n",
      "I0903 22:45:00.625844  3004 net.cpp:141] Setting up accuracy\n",
      "I0903 22:45:00.625859  3004 net.cpp:148] Top shape: (1)\n",
      "I0903 22:45:00.625869  3004 net.cpp:156] Memory required for data: 17478148\n",
      "I0903 22:45:00.625879  3004 layer_factory.hpp:77] Creating layer loss\n",
      "I0903 22:45:00.625892  3004 net.cpp:91] Creating Layer loss\n",
      "I0903 22:45:00.625905  3004 net.cpp:425] loss <- ip2_ip2_0_split_1\n",
      "I0903 22:45:00.625916  3004 net.cpp:425] loss <- label_data_1_split_1\n",
      "I0903 22:45:00.625931  3004 net.cpp:399] loss -> (automatic)\n",
      "I0903 22:45:00.625951  3004 layer_factory.hpp:77] Creating layer loss\n",
      "I0903 22:45:00.626133  3004 net.cpp:141] Setting up loss\n",
      "I0903 22:45:00.626152  3004 net.cpp:148] Top shape: (1)\n",
      "I0903 22:45:00.626165  3004 net.cpp:151]     with loss weight 1\n",
      "I0903 22:45:00.626185  3004 net.cpp:156] Memory required for data: 17478152\n",
      "I0903 22:45:00.626200  3004 net.cpp:217] loss needs backward computation.\n",
      "I0903 22:45:00.626211  3004 net.cpp:219] accuracy does not need backward computation.\n",
      "I0903 22:45:00.626224  3004 net.cpp:217] ip2_ip2_0_split needs backward computation.\n",
      "I0903 22:45:00.626236  3004 net.cpp:217] ip2 needs backward computation.\n",
      "I0903 22:45:00.626246  3004 net.cpp:217] relu1 needs backward computation.\n",
      "I0903 22:45:00.626260  3004 net.cpp:217] ip1 needs backward computation.\n",
      "I0903 22:45:00.626271  3004 net.cpp:217] pool2 needs backward computation.\n",
      "I0903 22:45:00.626281  3004 net.cpp:217] relu2 needs backward computation.\n",
      "I0903 22:45:00.626289  3004 net.cpp:217] conv2 needs backward computation.\n",
      "I0903 22:45:00.626299  3004 net.cpp:217] pool1 needs backward computation.\n",
      "I0903 22:45:00.626309  3004 net.cpp:217] relu1 needs backward computation.\n",
      "I0903 22:45:00.626319  3004 net.cpp:217] conv1 needs backward computation.\n",
      "I0903 22:45:00.626330  3004 net.cpp:219] label_data_1_split does not need backward computation.\n",
      "I0903 22:45:00.626341  3004 net.cpp:219] data does not need backward computation.\n",
      "I0903 22:45:00.626350  3004 net.cpp:261] This network produces output accuracy\n",
      "I0903 22:45:00.626381  3004 net.cpp:274] Network initialization done.\n",
      "I0903 22:45:00.626498  3004 solver.cpp:60] Solver scaffolding done.\n",
      "I0903 22:45:00.627164  3004 caffe.cpp:226] Starting Optimization\n",
      "I0903 22:45:00.627184  3004 solver.cpp:279] Solving mnist-net\n",
      "I0903 22:45:00.627194  3004 solver.cpp:280] Learning Rate Policy: step\n",
      "I0903 22:45:00.628271  3004 solver.cpp:337] Iteration 0, Testing net (#0)\n",
      "I0903 22:45:10.253593  3004 solver.cpp:404]     Test net output #0: accuracy = 0.0635547\n",
      "I0903 22:45:10.278435  3004 solver.cpp:228] Iteration 0, loss = 2.33798\n",
      "I0903 22:45:10.278488  3004 sgd_solver.cpp:106] Iteration 0, lr = 0.001\n",
      "I0903 22:48:17.953963  3004 solver.cpp:454] Snapshotting to binary proto file ./models/mnist_iter_5000.caffemodel\n",
      "I0903 22:48:17.970677  3004 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./models/mnist_iter_5000.solverstate\n",
      "I0903 22:48:17.971822  3004 solver.cpp:337] Iteration 5000, Testing net (#0)\n",
      "I0903 22:48:26.543581  3004 solver.cpp:404]     Test net output #0: accuracy = 0.978372\n",
      "I0903 22:48:26.566208  3004 solver.cpp:228] Iteration 5000, loss = 0.033492\n",
      "I0903 22:48:26.566251  3004 sgd_solver.cpp:106] Iteration 5000, lr = 0.001\n",
      "I0903 22:51:34.389183  3004 solver.cpp:454] Snapshotting to binary proto file ./models/mnist_iter_10000.caffemodel\n",
      "I0903 22:51:34.405000  3004 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./models/mnist_iter_10000.solverstate\n",
      "I0903 22:51:34.406167  3004 solver.cpp:337] Iteration 10000, Testing net (#0)\n",
      "I0903 22:51:43.069819  3004 solver.cpp:404]     Test net output #0: accuracy = 0.983867\n",
      "I0903 22:51:43.094418  3004 solver.cpp:228] Iteration 10000, loss = 0.0155501\n",
      "I0903 22:51:43.094450  3004 sgd_solver.cpp:106] Iteration 10000, lr = 0.001\n",
      "I0903 22:54:50.636843  3004 solver.cpp:454] Snapshotting to binary proto file ./models/mnist_iter_15000.caffemodel\n",
      "I0903 22:54:50.653540  3004 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./models/mnist_iter_15000.solverstate\n",
      "I0903 22:54:50.654512  3004 solver.cpp:337] Iteration 15000, Testing net (#0)\n",
      "I0903 22:55:00.023437  3004 solver.cpp:404]     Test net output #0: accuracy = 0.986419\n",
      "I0903 22:55:00.045380  3004 solver.cpp:228] Iteration 15000, loss = 0.0136831\n",
      "I0903 22:55:00.045420  3004 sgd_solver.cpp:106] Iteration 15000, lr = 0.001\n",
      "I0903 22:58:10.456941  3004 solver.cpp:454] Snapshotting to binary proto file ./models/mnist_iter_20000.caffemodel\n",
      "I0903 22:58:10.472870  3004 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./models/mnist_iter_20000.solverstate\n",
      "I0903 22:58:10.487799  3004 solver.cpp:317] Iteration 20000, loss = 0.0119137\n",
      "I0903 22:58:10.487835  3004 solver.cpp:337] Iteration 20000, Testing net (#0)\n",
      "I0903 22:58:18.839176  3004 solver.cpp:404]     Test net output #0: accuracy = 0.986484\n",
      "I0903 22:58:18.839215  3004 solver.cpp:322] Optimization Done.\n",
      "I0903 22:58:18.839221  3004 caffe.cpp:229] Optimization Done.\n"
     ]
    }
   ],
   "source": [
    "!./scripts/train.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试 Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过训练，终于可以进行测试了。我们需要读入test.csv的内容，然后对于里面的每一个测试用例进行前向计算，得到对应的输出，作为预测。\n",
    "\n",
    "After the training, we can test out model. We need to read the test imges and forward fill the net to get the predication labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_batch_images(lines):\n",
    "    \"\"\"\n",
    "    get batch images for testing\n",
    "    \"\"\"\n",
    "    total_size = len(lines)\n",
    "    images = np.empty((total_size, 28, 28, 1), dtype = np.float32)\n",
    "    for i, line in enumerate(lines):\n",
    "        splited = line.strip().split(',')\n",
    "        data = [float(x) for x in splited]\n",
    "        images[i] = np.array(data).astype(np.float32).reshape((28, 28, 1))\n",
    "    return images\n",
    "\n",
    "def get_pred_label(cls, images, gt, verbose = True):\n",
    "    \"\"\"\n",
    "    use cls to predict the label, gt is groundtruth for debugging\n",
    "    When test, set gt = None, verbose = False\n",
    "    \"\"\"\n",
    "    pred = cls.predict(images)\n",
    "    n, c = pred.shape\n",
    "    label = np.argmax(pred, axis = 1).astype(int)\n",
    "    prob = pred[xrange(n), label]\n",
    "    if verbose:\n",
    "        for i in xrange(n):\n",
    "            print 'idx {0}: label {1}, prob {2}, gt: {3}'.format(i, label[i], prob[i], gt[i])\n",
    "    return label\n",
    "\n",
    "def test(cls, csv_file, phase = 'test', head = None):\n",
    "    \"\"\"\n",
    "    give the prediction of the images in csv_file\n",
    "    \"\"\"\n",
    "    with open(csv_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    if head is None:\n",
    "        head = 10\n",
    "    lines = lines[1:]\n",
    "    lines = lines[:head]\n",
    "    imgs = np.empty((head, 28, 28, 1), dtype = np.float32)\n",
    "    gt = np.empty((head, 1), dtype = int)\n",
    "    for i, line in enumerate(lines):\n",
    "        splited = line.strip().split(',')\n",
    "        data = [float(x) for x in splited]\n",
    "        gt[i] = int(data[0])\n",
    "        imgs[i] = np.array(data[1:], dtype = np.float32).reshape((28, 28, 1))\n",
    "    get_pred_label(cls, imgs, gt)\n",
    "\n",
    "def get_final_tes_res(cls, input_csv_file, output_csv_file):\n",
    "    \"\"\"\n",
    "    the function invoked in main function\n",
    "    read test samples from input_csv_file\n",
    "    write the prediction results to output_csv_file\n",
    "    \"\"\"\n",
    "    with open(input_csv_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    lines = lines[1:]\n",
    "    total_img_num = len(lines)\n",
    "    batch = 1000\n",
    "    groups = total_img_num / batch\n",
    "    if total_img_num % batch:\n",
    "        groups += 1\n",
    "    print 'total test imge number: {0}'.format(total_img_num)\n",
    "    print 'batch size: {0}, total group: {1}'.format(batch, groups)\n",
    "    print '----------------------------'\n",
    "    labels = np.empty((total_img_num, 1), dtype = int)\n",
    "\n",
    "    for i in xrange(groups):\n",
    "        start, end = batch*i, batch*(i+1)\n",
    "        if i == groups-1:\n",
    "            end = total_img_num\n",
    "        line_batch = lines[start: end]\n",
    "        images = get_batch_images(line_batch)\n",
    "        pred_label = get_pred_label(cls, images, None, False)\n",
    "        labels[start: end] = pred_label.reshape((-1, 1))\n",
    "        print 'group {0} has been processed.'.format(i+1)\n",
    "        \n",
    "    with open(output_csv_file, 'w') as f:\n",
    "        f.write('ImageId,Label\\n')\n",
    "        for i in xrange(total_img_num):\n",
    "            f.write('{0},{1}\\n'.format(i+1, labels[i, 0]))\n",
    "\n",
    "\n",
    "class Classfier(caffe.Net):\n",
    "    \"\"\"\n",
    "    Classifier extends caffe.Net for mnist class prediction\n",
    "    \"\"\"\n",
    "    def __init__(self, model_file, weight_file):\n",
    "        \"\"\"\n",
    "        initialization function, model file and weight file should\n",
    "        be provided\n",
    "        \"\"\"\n",
    "        caffe.Net.__init__(self, model_file, weight_file, caffe.TEST)\n",
    "        self.input_size = (28, 28)\n",
    "        in_ = self.inputs[0]\n",
    "        self.transformer = caffe.io.Transformer(\n",
    "            {in_: self.blobs[in_].data.shape for in_ in self.inputs})\n",
    "        self.transformer.set_transpose(in_, (2, 0, 1))\n",
    "        self.transformer.set_mean(in_, np.array([128.0]))\n",
    "        self.transformer.set_input_scale(in_, 1.0/255)\n",
    "    def predict(self, inputs):\n",
    "        \"\"\"\n",
    "        predict classification probabilities of inputs\n",
    "        \"\"\"\n",
    "        input_ = np.zeros((len(inputs),) + self.input_size + (1,), dtype = np.float32)\n",
    "        for ix, in_ in enumerate(inputs):\n",
    "            input_[ix] = caffe.io.resize_image(in_, self.input_size).reshape((28, 28, 1))\n",
    "\n",
    "        # classify\n",
    "        caffe_in = np.zeros(np.array(input_.shape)[[0, 3, 1, 2]], dtype=np.float32)\n",
    "        for ix, in_ in enumerate(input_):\n",
    "            caffe_in[ix] = self.transformer.preprocess(self.inputs[0], in_)\n",
    "        out = self.forward_all(**{self.inputs[0]: caffe_in})\n",
    "        pred = out[self.outputs[0]]\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total test imge number: 28000\n",
      "batch size: 1000, total group: 28\n",
      "----------------------------\n",
      "group 1 has been processed.\n",
      "group 2 has been processed.\n",
      "group 3 has been processed.\n",
      "group 4 has been processed.\n",
      "group 5 has been processed.\n",
      "group 6 has been processed.\n",
      "group 7 has been processed.\n",
      "group 8 has been processed.\n",
      "group 9 has been processed.\n",
      "group 10 has been processed.\n",
      "group 11 has been processed.\n",
      "group 12 has been processed.\n",
      "group 13 has been processed.\n",
      "group 14 has been processed.\n",
      "group 15 has been processed.\n",
      "group 16 has been processed.\n",
      "group 17 has been processed.\n",
      "group 18 has been processed.\n",
      "group 19 has been processed.\n",
      "group 20 has been processed.\n",
      "group 21 has been processed.\n",
      "group 22 has been processed.\n",
      "group 23 has been processed.\n",
      "group 24 has been processed.\n",
      "group 25 has been processed.\n",
      "group 26 has been processed.\n",
      "group 27 has been processed.\n",
      "group 28 has been processed.\n"
     ]
    }
   ],
   "source": [
    "model_file = './net/deploy.prototxt'\n",
    "weight_file = './models/mnist_iter_20000.caffemodel'\n",
    "cls = Classfier(model_file, weight_file)\n",
    "  \n",
    "test_csv = './data/test.csv'\n",
    "output_file = './data/submit.csv'\n",
    "get_final_tes_res(cls, test_csv, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提交结果 Submition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以将结果提交到Kaggle的网站进行评比。我的模型精度为98.600%.\n",
    "\n",
    "Submit your results to the website and get your rank! My model's accuracy is 98.600%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
